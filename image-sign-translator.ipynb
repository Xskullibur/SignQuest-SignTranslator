{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('datasets/images/sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('datasets/images/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27455 entries, 0 to 27454\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 164.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27450</th>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>234</td>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451</th>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27452</th>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27453</th>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27454</th>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>194</td>\n",
       "      <td>214</td>\n",
       "      <td>203</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>209</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27455 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          3     107     118     127     134     139     143     146     150   \n",
       "1          6     155     157     156     156     156     157     156     158   \n",
       "2          2     187     188     188     187     187     186     187     188   \n",
       "3          2     211     211     212     212     211     210     211     210   \n",
       "4         13     164     167     170     172     176     179     180     184   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27450     13     189     189     190     190     192     193     193     193   \n",
       "27451     23     151     154     157     158     160     161     163     164   \n",
       "27452     18     174     174     174     174     174     175     175     174   \n",
       "27453     17     177     181     184     185     187     189     190     191   \n",
       "27454     23     179     180     180     180     182     181     182     183   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         153  ...       207       207       207       207       206   \n",
       "1         158  ...        69       149       128        87        94   \n",
       "2         187  ...       202       201       200       199       198   \n",
       "3         210  ...       235       234       233       231       230   \n",
       "4         185  ...        92       105       105       108       133   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27450     193  ...       132       165        99        77        52   \n",
       "27451     166  ...       198       198       198       198       198   \n",
       "27452     173  ...       121       196       209       208       206   \n",
       "27453     191  ...       119        56        27        58       102   \n",
       "27454     182  ...       108       132       170       194       214   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           206       206       204       203       202  \n",
       "1           163       175       103       135       149  \n",
       "2           199       198       195       194       195  \n",
       "3           226       225       222       229       163  \n",
       "4           163       157       163       164       179  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27450       200       234       200       222       225  \n",
       "27451       196       195       195       195       194  \n",
       "27452       204       203       202       200       200  \n",
       "27453        79        47        64        87        93  \n",
       "27454       203       197       205       209       215  \n",
       "\n",
       "[27455 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-433200328ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabel_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\work\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \"\"\"\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\work\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'multioutput'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             raise ValueError(\"Multioutput target data is not supported with \"\n\u001b[0m\u001b[0;32m    432\u001b[0m                              \"label binarization\")\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(train_data)\n",
    "y_test = label_binarizer.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import one_hot\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_images = (train_data.iloc[:, 1:] / 255).to_numpy().reshape((-1, 28, 28, 1))\n",
    "\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_images = (test_data.iloc[:, 1:] / 255).to_numpy().reshape((-1, 28, 28, 1))\n",
    "\n",
    "train_labels_onehot = one_hot(train_labels, 25).numpy()\n",
    "test_labels_onehot = one_hot(test_labels, 25).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_onehot[27454]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                12825     \n",
      "=================================================================\n",
      "Total params: 264,562\n",
      "Trainable params: 264,262\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, DepthwiseConv2D, Conv2D, MaxPool2D, BatchNormalization, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Dense(784, activation='relu'))\n",
    "# model.add(Dense(392, activation='relu'))\n",
    "# model.add(Dense(196, activation='relu'))\n",
    "# model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(200 , (6,6), strides = 1, padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(175, (5,5), strides = 1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(150, (5,5), strides = 1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(125, (4,4), strides = 1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(100, (4,4), strides = 1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2) , strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2) , strides = 2, padding = 'same'))\n",
    "# model.add(Conv2D(25 , (3,3) , strides = 1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2) , strides = 2, padding = 'same'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units = 512 , activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(units = 25 , activation = 'softmax'))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 25 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(75, (3,3), strides=1, padding = 'same' , activation = 'relu', input_shape = (28,28,1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Conv2D(50, (3,3), strides=1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2) , strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Conv2D(25, (3,3), strides=1, padding = 'same' , activation = 'relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D((2,2) , strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units = 512 , activation = 'relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(units = 24, activation = 'softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 215 steps, validate on 7172 samples\n",
      "Epoch 1/40\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 1.7855 - accuracy: 0.4327 - val_loss: 4.3797 - val_accuracy: 0.1207\n",
      "Epoch 2/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.7323 - accuracy: 0.7496 - val_loss: 3.5512 - val_accuracy: 0.2659\n",
      "Epoch 3/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.4305 - accuracy: 0.8526 - val_loss: 0.5406 - val_accuracy: 0.8041\n",
      "Epoch 4/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.2901 - accuracy: 0.9010 - val_loss: 0.3043 - val_accuracy: 0.8982\n",
      "Epoch 5/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.2161 - accuracy: 0.9278 - val_loss: 0.3695 - val_accuracy: 0.8882\n",
      "Epoch 6/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.1796 - accuracy: 0.9395 - val_loss: 0.0897 - val_accuracy: 0.9693\n",
      "Epoch 7/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.1469 - accuracy: 0.9498 - val_loss: 0.1083 - val_accuracy: 0.9633\n",
      "Epoch 8/40\n",
      "213/215 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9540 ETA: 0s - loss: 0\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.1324 - accuracy: 0.9540 - val_loss: 0.1288 - val_accuracy: 0.9534\n",
      "Epoch 9/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.0892 - accuracy: 0.9702 - val_loss: 0.0211 - val_accuracy: 0.9951\n",
      "Epoch 10/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.0833 - val_accuracy: 0.9704\n",
      "Epoch 11/40\n",
      "214/215 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9789\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.0292 - val_accuracy: 0.9883\n",
      "Epoch 12/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.0169 - val_accuracy: 0.9941\n",
      "Epoch 13/40\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0507 - accuracy: 0.9840 - val_loss: 0.0122 - val_accuracy: 0.9965\n",
      "Epoch 14/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.0119 - val_accuracy: 0.9976\n",
      "Epoch 15/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
      "Epoch 16/40\n",
      "213/215 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9839\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0196 - val_accuracy: 0.9943\n",
      "Epoch 17/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.0129 - val_accuracy: 0.9965\n",
      "Epoch 18/40\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.0078 - val_accuracy: 0.9992\n",
      "Epoch 19/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.0101 - val_accuracy: 0.9969\n",
      "Epoch 20/40\n",
      "213/215 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9885\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 21/40\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 22/40\n",
      "214/215 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9902\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
      "Epoch 23/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
      "Epoch 24/40\n",
      "213/215 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9899\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 25/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 26/40\n",
      "214/215 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.0077 - val_accuracy: 0.9985\n",
      "Epoch 27/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 28/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 29/40\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
      "Epoch 30/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0079 - val_accuracy: 0.9986\n",
      "Epoch 31/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.0069 - val_accuracy: 0.9987\n",
      "Epoch 32/40\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 33/40\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 34/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
      "Epoch 35/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 36/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 37/40\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
      "Epoch 38/40\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
      "Epoch 39/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
      "Epoch 40/40\n",
      "215/215 [==============================] - 6s 30ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0059 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6a03da048>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lrdecay = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "model.fit(datagen.flow(train_images,train_labels_onehot, batch_size = 128), epochs=40, validation_data = (test_images, test_labels_onehot), callbacks = [learning_rate_reduction])\n",
    "# history = model.fit(datagen.flow(train_images,y_train, batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                12825     \n",
      "=================================================================\n",
      "Total params: 264,562\n",
      "Trainable params: 264,262\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  5 10 ...  2  4  2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predict_test_labels = np.argmax(model.predict(test_images), axis=-1)\n",
    "print(predict_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9989203076674514\n",
      "Recall: 0.9992323581914251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "#confusion_matrix(test_labels, predict_test_labels)\n",
    "print('Precision: {}'.format(precision_score(test_labels, predict_test_labels, average='macro')))\n",
    "print('Recall: {}'.format(recall_score(test_labels, predict_test_labels, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b6f3ff0bb9bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test/185.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test/185.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "img = cv2.flip(img, 1)\n",
    "img = img / 255\n",
    "                     \n",
    "#Show the image with matplotlib\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('data2/A/1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "# img = cv2.rotate(cv2.resize(img, (28, 28), interpolation = cv2.INTER_AREA), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "# brightness = 50\n",
    "# contrast = 30\n",
    "# img = np.int16(img)\n",
    "# img = img * (contrast/127+1) - contrast + brightness\n",
    "# img = np.clip(img, 0, 255)\n",
    "# img = np.uint8(img)\n",
    "\n",
    "# img = img / 255\n",
    "                     \n",
    "#Show the image with matplotlib\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "    9: 'K',\n",
    "    10: 'L',\n",
    "    11: 'M',\n",
    "    12: 'N',\n",
    "    13: 'O',\n",
    "    14: 'P',\n",
    "    15: 'Q',\n",
    "    16: 'R',\n",
    "    17: 'S',\n",
    "    18: 'T',\n",
    "    19: 'U',\n",
    "    20: 'V',\n",
    "    21: 'W',\n",
    "    22: 'X',\n",
    "    23: 'Y'\n",
    "}\n",
    "\n",
    "\n",
    "predicted_index = np.argmax(model.predict(img.reshape((-1, 28, 28, 1))))\n",
    "print(model.predict(img.reshape((-1, 28, 28, 1))))\n",
    "chars[predicted_index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tools\\Anaconda3\\envs\\work\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tools\\Anaconda3\\envs\\work\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: christina-small\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: christina-small\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('christina-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('christina-small-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.lite.TFLiteConverter import from_saved_model\n",
    "# from tensorflow.io.gfile import GFile\n",
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('christina')\n",
    "tflite_model = converter.convert()\n",
    "with tf.io.gfile.GFile('christina.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_images).reshape(-1,28, 28).shape)\n",
    "\n",
    "for i, img in enumerate(np.array(test_images).reshape(-1,28, 28)):\n",
    "    cv2.imwrite('./test/'+str(i)+'.jpg', img*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
